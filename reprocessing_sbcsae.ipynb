{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba668fab",
   "metadata": {},
   "source": [
    "Maya Asher, 4/8/24\n",
    "# Reprocessing the Santa Barbara Corpus of Spoken American English\n",
    "- **NEW REPLACEMENT for progress report 2**\n",
    "- **EXISTING for progress report 3**\n",
    "\n",
    "The SBCSAE is a collection of time-aligned transcripts of audio files. Along with timestamps, the transcripts also include many non-alphabetic characters that denote different aspects of the speech. \n",
    "\n",
    "In this notebook, I process and clean up the raw text so that I can easily search for and locate my target words in my later analysis. Specifically, I read in the files, put each transcript into individual dfs, separate them by column count, and pickle the three lists of dfs.\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae7fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391ffd0",
   "metadata": {},
   "source": [
    "## Read in files\n",
    "Originially, there were parsing errors with almost half the files, so I had to manually go through and fix some of the spacing in the files. I opened them in Atom, found the line with issues, and fixed the spacing, which usually just consisted of removing an extraneous tab.\n",
    "\n",
    "Now, all 43 TRN files are able to be read in and inserted into an individual Pandas df, which is stored in the list `data_frames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7c9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder with necessary files\n",
    "directory = \"/Users/mayaasher/data_science/Stance-Taking-in-Spontaneous-Speech/data/utf-16/\"\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# only files ending in .trn\n",
    "files = [file for file in files if file.endswith('.trn')]\n",
    "\n",
    "# sort files based on numerical order\n",
    "sorted_files = sorted(files, key=lambda x: int(x.split('.')[0][4:]))\n",
    "\n",
    "#list to hold all dfs\n",
    "data_frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47ab1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all files IN ORDER!!!\n",
    "for file_name in sorted_files:\n",
    "    try:\n",
    "        filename = file_name\n",
    "        data = pd.read_csv(directory+filename, sep='\\t', header=None, encoding='utf-16-be')\n",
    "        df = pd.DataFrame(data)\n",
    "        data_frames.append(df)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing {filename}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c59fa0",
   "metadata": {},
   "source": [
    "## Column issues\n",
    "Unfortunately, the dfs have varying numbers of columns (2, 3, and 4 columns). The 2 and 3 column dfs have timestamps that go to the hundredths place while the 4 column dfs go to the thousandths place, so perhaps that caused processing issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6151d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0                                         1\n",
      "0  0.00 2.53  FRED:                                    ... Okay.\n",
      "1   2.53 4.73                              One= large loan (Hx),\n",
      "2   4.73 6.23                                  ... renewed (Hx),\n",
      "3   6.23 8.08           ... a hundred ninety-seven= .. thousand,\n",
      "4   8.08 9.23                          a hundred eighty dollars.\n",
      "           0         1                                  2\n",
      "0  0.00 1.24  KEVIN:     Is that just [carbonated water]?\n",
      "1  0.45 1.24  WENDY:                      [No thank you].\n",
      "2  1.24 1.50                                        [2No,\n",
      "3  1.24 3.38  KEN:      [2(H) No this is2] crea=m [3soda.\n",
      "4  1.50 2.36  WENDY:                   It's cream soda2].\n",
      "       0      1        2                                                  3\n",
      "0  2.660  2.805  JOANNE:                                               But,\n",
      "1  2.805  4.685      NaN  so these slides <X should X> be real interesting.\n",
      "2  6.140  6.325     KEN:                                          ... Yeah.\n",
      "3  6.325  7.710      NaN                  I think it'll be real interesting\n",
      "4  7.710  8.535      NaN                           I think it'll be a real,\n"
     ]
    }
   ],
   "source": [
    "print(data_frames[12].head())\n",
    "print(data_frames[11].head())\n",
    "print(data_frames[13].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937ce4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1312, 3)\n",
      "1 (1419, 3)\n",
      "2 (1546, 3)\n",
      "3 (1298, 3)\n",
      "4 (826, 3)\n",
      "5 (1767, 3)\n",
      "6 (731, 3)\n",
      "7 (1496, 3)\n",
      "8 (725, 3)\n",
      "9 (1107, 3)\n",
      "10 (996, 3)\n",
      "11 (2259, 3)\n",
      "12 (1189, 2)\n",
      "13 (1984, 4)\n",
      "14 (1518, 4)\n",
      "15 (1169, 4)\n",
      "16 (566, 4)\n",
      "17 (1266, 4)\n",
      "18 (705, 4)\n",
      "19 (1518, 4)\n",
      "20 (875, 4)\n",
      "21 (1214, 4)\n",
      "22 (1539, 4)\n",
      "23 (1845, 4)\n",
      "24 (818, 4)\n",
      "25 (739, 4)\n",
      "26 (1330, 4)\n",
      "27 (1822, 4)\n",
      "28 (978, 4)\n",
      "29 (719, 4)\n",
      "30 (1497, 4)\n",
      "31 (1431, 4)\n",
      "32 (1197, 4)\n",
      "33 (1162, 4)\n",
      "34 (1128, 4)\n",
      "35 (1273, 4)\n",
      "36 (959, 4)\n",
      "37 (1681, 4)\n",
      "38 (1600, 4)\n",
      "39 (1012, 4)\n",
      "40 (982, 4)\n",
      "41 (1857, 4)\n",
      "42 (1013, 4)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for frame in data_frames:\n",
    "    print(count, frame.shape)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d3f42",
   "metadata": {},
   "source": [
    "## Column issue work-around\n",
    "For the sake of searching the dfs, I'm separating them out into 3 lists depending on their column count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "246f22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2c = data_frames[12]\n",
    "dfs_3c = data_frames[:11]\n",
    "dfs_4c = data_frames[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd68400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# only 1 in df_2c\n",
    "print(len(dfs_3c))\n",
    "print(len(dfs_4c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3733cd1",
   "metadata": {},
   "source": [
    "## Pickle\n",
    "I'm pickling the dfs so they can be used in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13cd3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df2col.pkl', 'wb')\n",
    "pickle.dump(df_2c, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b8a1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df3col.pkl', 'wb')\n",
    "pickle.dump(dfs_3c, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3a56cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df4col.pkl', 'wb')\n",
    "pickle.dump(dfs_4c, f, -1)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
