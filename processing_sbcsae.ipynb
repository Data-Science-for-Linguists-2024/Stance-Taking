{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fb8651",
   "metadata": {},
   "source": [
    "Maya Asher, 2/13/24\n",
    "# Processing Santa Barbara Corpus of Spoken American English\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52ec2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from statistics import mean \n",
    "import re\n",
    "import io\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc6e79",
   "metadata": {},
   "source": [
    "## Read in correct files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7b874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put trn files into a dict\n",
    "path = \"/Users/mayaasher/data_science/Stance-Taking-in-Spontaneous-Speech/data/utf-16\"\n",
    "os.chdir(path)\n",
    "txt_dict = {}\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".trn\"): \n",
    "        filename = file\n",
    "        f = open(path+'/'+filename, 'r', encoding='utf-16-be') # have to specify utf-16 big-endian\n",
    "        text = f.read()\n",
    "        txt_dict[str(filename)] = str(text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc7c697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4f00bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SBC034.trn', 'SBC008.trn', 'SBC009.trn', 'SBC035.trn', 'SBC023.trn', 'SBC037.trn', 'SBC036.trn', 'SBC022.trn', 'SBC032.trn', 'SBC033.trn', 'SBC019.trn', 'SBC031.trn', 'SBC024.trn', 'SBC018.trn', 'SBC057.trn', 'SBC043.trn', 'SBC042.trn', 'SBC056.trn', 'SBC045.trn', 'SBC051.trn', 'SBC050.trn', 'SBC044.trn', 'SBC047.trn', 'SBC049.trn', 'SBC048.trn', 'SBC060.trn', 'SBC058.trn', 'SBC059.trn', 'SBC015.trn', 'SBC001.trn', 'SBC029.trn', 'SBC014.trn', 'SBC002.trn', 'SBC016.trn', 'SBC017.trn', 'SBC003.trn', 'SBC007.trn', 'SBC013.trn', 'SBC006.trn', 'SBC010.trn', 'SBC004.trn', 'SBC005.trn', 'SBC011.trn'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dict.keys() # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40c81cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿0.000\t4.475\t>ENV:\t((DOOR_OPENING_AND_CLOSING))\n",
      "4.475\t5.077\tKAREN:\tHi sweetie.\n",
      "5.077\t5.908\tSCOTT:\t... Hey.\n",
      "5.908\t6.489\t\t.. (THROAT)\n",
      "6.489\t7.630\tKAREN:\t<X Sweetie frumptions X>.\n",
      "7.630\t10.399\t\t... This is kinda open.\n",
      "10.399\t11.071\tSCOTT:\t... Yep.\n",
      "11.071\t12.008\t\t... How was work?\n",
      "12.008\t13.158\t>ENV:\t((CLOSET))\n",
      "13.158\t13.889\tKAREN:\tI'm so tired.\n",
      "13.889\t15.155\tSCOTT:\t... Ti=red.\n",
      "15.155\t15.743\tKAREN:\tIt was % --\n",
      "15.743\t16.277\t\tIt was okay,\n",
      "16.277\t16.939\t\tI left my bag there.\n",
      "16.939\t17.809\t\t... <VOX I left my bag,\n",
      "17.809\t18.523\t\tand all my money,\n",
      "18.523\t19.574\t\tand all my things= VOX>.\n",
      "19.574\t21.174\tSCOTT:\t... N[ow the gho]sts'll get it.\n",
      "20.268\t20.558\tKAREN:\t[They ca-] --\n",
      "21.174\t22.600\t\t... <@ Ghosts'll get it @>,\n",
      "22.600\t23.958\t\t... that's okay.\n",
      "23.958\t24.901\t\t... (TSK) (H)\n",
      "24.901\t25.505\t\t... Um,\n",
      "25.505\t27.246\t\t... (TSK) (H)\n",
      "27.246\t27.954\t\t... ten thirty,\n",
      "27.954\t29.582\t\tthere were probably .. thirty people in the store.\n",
      "29.582\t30.762\tSCOTT:\t... Good grief.\n",
      "30.762\t31.063\tKAREN:\tWe're like,\n",
      "31.\n"
     ]
    }
   ],
   "source": [
    "print(txt_dict['SBC034.trn'][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e62b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeff0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSING))\\n4.475\\t5.077\\tKAREN:\\tHi sweetie.\\n5.077\\t5.908\\tSCOTT:\\t... Hey.\\n5.908\\t6.489\\t\\t.. (THROAT)\\n6.489\\t7.630\\tKAREN:\\t<X Sweetie frumptions X>.\\n7.630\\t10.399\\t\\t... This is kinda open.\\n10.399\\t11.071\\tSCOTT:\\t... Yep.\\n11.071\\t12.008\\t\\t... How was work?\\n12.008\\t13.158\\t>ENV:\\t((CLOSET))\\n13.158\\t13.889\\tKAREN:\\tI'm so tired.\\n13.889\\t15.155\\tSCOTT:\\t... Ti=red.\\n15.155\\t15.743\\tKAREN:\\tIt was % --\\n15.743\\t16.277\\t\\tIt was okay,\\n16.277\\t16.939\\t\\tI left my bag there.\\n16.939\\t17.809\\t\\t... <VOX I left my bag,\\n17.809\\t18.523\\t\\tand all my money,\\n18.523\\t19.574\\t\\tand all my things= VOX>.\\n19.574\\t21.174\\tSCOTT:\\t... N[ow the gho]sts'll get it.\\n20.268\\t20.558\\tKAREN:\\t[They ca-] --\\n21.174\\t22.600\\t\\t... <@ Ghosts'll get it @>,\\n22.600\\t23.958\\t\\t... that's okay.\\n23.958\\t24.901\\t\\t... (TSK) (H)\\n24.901\\t25.505\\t\\t... Um,\\n25.505\\t27.246\\t\\t... (TSK) (H)\\n27.246\\t27.954\\t\\t... ten thirty,\\n27.954\\t29.582\\t\\tthere were probably .. thirty people in the store.\\n29.582\\t30.762\\tSCOTT:\\t... Good grief.\\n30.762\\t31.063\\tKAREN:\\tWe're like,\\n31.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dict['SBC034.trn'][:1000] # gotta clean this up..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06135266",
   "metadata": {},
   "source": [
    "## Clean up text\n",
    "### Toy data \n",
    "We basically want to get rid of all non-alphabetic characters in each 'value' of the dictionary (each string/transcript). Let's work with a toy string first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ddf6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeff0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSING))\\n4.475\\t5.077\\tKAREN:\\tHi sweetie.\\n5.077\\t5.908\\tSCOTT:\\t... Hey.\\n5.908\\t6.489\\t\\t.. (THROAT)\\n6.489\\t7.630\\tKAREN:\\t<X Sweetie frumptions X>.\\n7.630\\t10.399\\t\\t... This is kinda open.\\n10.399\\t11.071\\tSCOTT:\\t... Yep.\\n11.071\\t12.008\\t\\t... How was work?\\n12.008\\t13.158\\t>ENV:\\t((CLOSET))\\n13.158\\t13.889\\tKAREN:\\tI'm so tired.\\n13.889\\t15.155\\tSCOTT:\\t... Ti=red.\\n15.155\\t15.743\\tKAREN:\\tIt was % --\\n15.743\\t16.277\\t\\tIt was okay,\\n16.277\\t16.939\\t\\tI left my bag there.\\n16.939\\t17.809\\t\\t... <VOX I left my bag,\\n17.809\\t18.523\\t\\tand all my money,\\n18.523\\t19.574\\t\\tand all my things= VOX>.\\n19.574\\t21.174\\tSCOTT:\\t... N[ow the gho]sts'll get it.\\n20.268\\t20.558\\tKAREN:\\t[They ca-] --\\n21.174\\t22.600\\t\\t... <@ Ghosts'll get it @>,\\n22.600\\t23.958\\t\\t... that's okay.\\n23.958\\t24.901\\t\\t... (TSK) (H)\\n24.901\\t25.505\\t\\t... Um,\\n25.505\\t27.246\\t\\t... (TSK) (H)\\n27.246\\t27.954\\t\\t... ten thirty,\\n27.954\\t29.582\\t\\tthere were probably .. thirty people in the store.\\n29.582\\t30.762\\tSCOTT:\\t... Good grief.\\n30.762\\t31.063\\tKAREN:\\tWe're like,\\n31.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy = \"\\ufeff0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSING))\\n4.475\\t5.077\\tKAREN:\\tHi sweetie.\\n5.077\\t5.908\\tSCOTT:\\t... Hey.\\n5.908\\t6.489\\t\\t.. (THROAT)\\n6.489\\t7.630\\tKAREN:\\t<X Sweetie frumptions X>.\\n7.630\\t10.399\\t\\t... This is kinda open.\\n10.399\\t11.071\\tSCOTT:\\t... Yep.\\n11.071\\t12.008\\t\\t... How was work?\\n12.008\\t13.158\\t>ENV:\\t((CLOSET))\\n13.158\\t13.889\\tKAREN:\\tI'm so tired.\\n13.889\\t15.155\\tSCOTT:\\t... Ti=red.\\n15.155\\t15.743\\tKAREN:\\tIt was % --\\n15.743\\t16.277\\t\\tIt was okay,\\n16.277\\t16.939\\t\\tI left my bag there.\\n16.939\\t17.809\\t\\t... <VOX I left my bag,\\n17.809\\t18.523\\t\\tand all my money,\\n18.523\\t19.574\\t\\tand all my things= VOX>.\\n19.574\\t21.174\\tSCOTT:\\t... N[ow the gho]sts'll get it.\\n20.268\\t20.558\\tKAREN:\\t[They ca-] --\\n21.174\\t22.600\\t\\t... <@ Ghosts'll get it @>,\\n22.600\\t23.958\\t\\t... that's okay.\\n23.958\\t24.901\\t\\t... (TSK) (H)\\n24.901\\t25.505\\t\\t... Um,\\n25.505\\t27.246\\t\\t... (TSK) (H)\\n27.246\\t27.954\\t\\t... ten thirty,\\n27.954\\t29.582\\t\\tthere were probably .. thirty people in the store.\\n29.582\\t30.762\\tSCOTT:\\t... Good grief.\\n30.762\\t31.063\\tKAREN:\\tWe're like,\\n31.\"\n",
    "toy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7048e7",
   "metadata": {},
   "source": [
    "`.splitlines()` will put each line of the string into a list and\n",
    "`split('\\t')` will break each line into it's parts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50211243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.475', '5.077', 'KAREN:', 'Hi sweetie.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.475\\t5.077\\tKAREN:\\tHi sweetie.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = toy.splitlines()[1] \n",
    "print(line.split('\\t'))\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a8c96",
   "metadata": {},
   "source": [
    "### Trying it for real\n",
    "Creating a dictionary that contains the file name as the value and a list of lists as the values. The larger list contains the entire transcript, and each smaller list contains a single line. I will then have to go in and remove what needs to be gone...good news is I can automatically remove indices 0, 1, and 2 because they are just time stamps and names. Or maybe I'll put it in a df...hmmmmmmmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676a7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn, text in txt_dict.items(): # iterate through each transcript\n",
    "    temp = []\n",
    "    split_lines = text.splitlines() # split each line into a list entry\n",
    "    for line in split_lines:\n",
    "        temp.append(line.split('\\t')) # split each line into its components\n",
    "    txt_dict[fn] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22fa4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.475', '5.077', 'KAREN:', 'Hi sweetie.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dict['SBC034.trn'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc2385a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\\ufeff0.000', '4.475', '>ENV:', '((DOOR_OPENING_AND_CLOSING))'], ['4.475', '5.077', 'KAREN:', 'Hi sweetie.'], ['5.077', '5.908', 'SCOTT:', '... Hey.'], ['5.908', '6.489', '', '.. (THROAT)'], ['6.489', '7.630', 'KAREN:', '<X Sweetie frumptions X>.'], ['7.630', '10.399', '', '... This is kinda open.'], ['10.399', '11.071', 'SCOTT:', '... Yep.'], ['11.071', '12.008', '', '... How was work?'], ['12.008', '13.158', '>ENV:', '((CLOSET))'], ['13.158', '13.889', 'KAREN:', \"I'm so tired.\"]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dict['SBC034.trn'][:10] # gotta clean this up..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353ad7a",
   "metadata": {},
   "source": [
    "### The specific things we want to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "551b2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/mayaasher/data_science/metadata/annotations.txt\", \"r\")\n",
    "removals = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33466c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santa Barbara Corpus of Spoken American English Part-II\n",
      "\n",
      "  \n",
      "\n",
      "Units \n",
      "    Intonation Unit\t\t\tRETURN \n",
      "    Truncated intonation unit\t\t-- \n",
      "    word\t\t\t\tSPACE \n",
      "    truncated word\t\t\t_ \n",
      "\n",
      "Speakers \n",
      "    Speaker identity/turn start\t\t: \n",
      "    Speech overlap\t\t\t[ ] \n",
      "\n",
      "Transitional Continuity \n",
      "    Final\t\t\t\t. \n",
      "    Continuing\t\t\t\t, \n",
      "    Appeal\t\t\t\t? \n",
      "\n",
      "Terminal Pitch Direction \n",
      "    Fall\t\t\t\t\\ \n",
      "    Rise\t\t\t\t/ \n",
      "    Level\t\t\t\t- \n",
      "\n",
      "Accent and Lengthening \n",
      "    Primary accent\t\t\t^ \n",
      "    Secondary accent\t\t\t' \n",
      "    Booster\t\t\t\t! \n",
      "    Lengthening\t\t\t\t= \n",
      "\n",
      "Tone \n",
      "    Fall\t\t\t\t\\ \n",
      "    Rise\t\t\t\t/ \n",
      "    Fall-rise\t\t\t\t\\/ \n",
      "    Rise-fall\t\t\t\t/\\ \n",
      "    Level\t\t\t\t- \n",
      "\n",
      "Pause \n",
      "    Long\t\t\t\t...(N) \n",
      "    Medium\t\t\t\t... \n",
      "    Short\t\t\t\t.. \n",
      "    Latching\t\t\t\t(0) \n",
      "\n",
      "Vocal Noises \n",
      "    Vocal noises\t\t\t( ) \n",
      "    Inhalation\t\t\t\t(H) \n",
      "    Exhalation\t\t\t\t(Hx) \n",
      "    Glottal stop\t\t\t% \n",
      "    Laughter\t\t\t\t@ \n",
      "\n",
      "Quality \n",
      "    Quality\t\t\t\t<Y  Y> \n",
      "    Laugh quality\t\t\t<@  @> \n",
      "    Quotation quality\t\t\t<Q  Q> \n",
      "    Multiple quality features\t\t<Y  <Z  Z>  Y> \n",
      "\n",
      "Phonetics \n",
      "    Phonetic transcription\t\t(/  /) \n",
      "\n",
      "Transcriber's Perspective \n",
      "    Researcher's comments\t\t((  )) \n",
      "    Uncertain hearing\t\t\t<X  X> \n",
      "    Indecipherable syllable\t\tX \n",
      "\n",
      "Specialized notation \n",
      "    Duration\t\t\t\t(N) \n",
      "    Intonation unit continued\t\t& \n",
      "    Intonation subunit boundary\t\t| \n",
      "    Embedded intonation unit\t\t<| |> \n",
      "    Reset \n",
      "    False start\t\t\t\t< >\n",
      "    Codeswitching\t\t\t<L2 L2> \n",
      "\n",
      "Non-transcription Lines \n",
      "    Comment\t\t\t\t$\n",
      "    Interlinear gloss\t\t\t$G\n",
      "\n",
      "Reserved Symbols \n",
      "    Phonemic/orthographic\t\t, \n",
      "    Morphosyntactic coding\t\t = * # { } \n",
      "    User-definable\t\t\t \" ~ ; \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(removals) # the specific chars we want to remove"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
