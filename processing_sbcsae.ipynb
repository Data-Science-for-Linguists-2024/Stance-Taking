{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fb8651",
   "metadata": {},
   "source": [
    "Maya Asher, 2/23/24\n",
    "# Processing the Santa Barbara Corpus of Spoken American English\n",
    "The SBCSAE is a collection of time-aligned transcripts of audio files. Along with timestamps, the transcripts also include many non-alphabetic characters that denote different aspects of the speech. In this notebook, I will be processing and cleaning up the raw text so that I can easily search for and locate my target words in my later analysis. \n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52ec2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import io\n",
    "import nltk\n",
    "from natsort import index_natsorted\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc6e79",
   "metadata": {},
   "source": [
    "## Read in correct files\n",
    "There are 43 TRN files that need to be imported from my folder. I've opened each, added the contents to the dictionary like {filename : text}, and then closed it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7b874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put trn files into a dict\n",
    "path = \"/Users/mayaasher/data_science/Stance-Taking-in-Spontaneous-Speech/data/utf-16\"\n",
    "os.chdir(path)\n",
    "txt_dict = {}\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".trn\"): \n",
    "        filename = file\n",
    "        f = open(path+'/'+filename, 'r', encoding='utf-16-be') # have to specify utf-16 big-endian\n",
    "        text = f.read()\n",
    "        txt_dict[str(filename)] = str(text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc7c697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4f00bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SBC034.trn', 'SBC008.trn', 'SBC009.trn', 'SBC035.trn', 'SBC023.trn', 'SBC037.trn', 'SBC036.trn', 'SBC022.trn', 'SBC032.trn', 'SBC033.trn', 'SBC019.trn', 'SBC031.trn', 'SBC024.trn', 'SBC018.trn', 'SBC057.trn', 'SBC043.trn', 'SBC042.trn', 'SBC056.trn', 'SBC045.trn', 'SBC051.trn', 'SBC050.trn', 'SBC044.trn', 'SBC047.trn', 'SBC049.trn', 'SBC048.trn', 'SBC060.trn', 'SBC058.trn', 'SBC059.trn', 'SBC015.trn', 'SBC001.trn', 'SBC029.trn', 'SBC014.trn', 'SBC002.trn', 'SBC016.trn', 'SBC017.trn', 'SBC003.trn', 'SBC007.trn', 'SBC013.trn', 'SBC006.trn', 'SBC010.trn', 'SBC004.trn', 'SBC005.trn', 'SBC011.trn'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dict.keys() # all files here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e62b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeff0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSING))\\n4.475\\t5.077\\tKAREN:\\tHi sweetie.\\n5.077\\t5.908\\tSCOTT:\\t... Hey.\\n5.908\\t6.489\\t\\t.. (THROAT)\\n6.489\\t7.630\\tKAREN:\\t<X Sweetie frumptions X>.\\n7.630\\t10.399\\t\\t... This is kinda open.\\n10.399\\t11.071\\tSCOTT:\\t... Yep.\\n11.071\\t12.008\\t\\t... How was work?\\n12.008\\t13.158\\t>ENV:\\t((CLOSET))\\n13.158\\t13.889\\tKAREN:\\tI'm so tired.\\n13.889\\t15.155\\tSCOTT:\\t... Ti=red.\\n15.155\\t15.743\\tKAREN:\\tIt was % --\\n15.743\\t16.277\\t\\tIt was okay,\\n16.277\\t16.939\\t\\tI left my bag there.\\n16.939\\t17.809\\t\\t... <VOX I \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dict['SBC034.trn'][:500] # text data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6f79b",
   "metadata": {},
   "source": [
    "## Dictionary -> DF\n",
    "The dictionary contains the raw text for each file, so I've put it into a pandas data frame for easier access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beba6f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBC034.trn</td>\n",
       "      <td>﻿0.000\\t4.475\\t&gt;ENV:\\t((DOOR_OPENING_AND_CLOSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBC008.trn</td>\n",
       "      <td>﻿0.00 3.40\\t&gt;ENV:   \\t((DOOR_OPENS)) &lt;&lt;TALK\\n3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBC009.trn</td>\n",
       "      <td>﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBC035.trn</td>\n",
       "      <td>﻿0.000\\t1.020\\tPATTY:\\t[It's not that bad,\\n0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBC023.trn</td>\n",
       "      <td>﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                                               Text\n",
       "0  SBC034.trn  ﻿0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSI...\n",
       "1  SBC008.trn  ﻿0.00 3.40\\t>ENV:   \\t((DOOR_OPENS)) <<TALK\\n3...\n",
       "2  SBC009.trn  ﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...\n",
       "3  SBC035.trn  ﻿0.000\\t1.020\\tPATTY:\\t[It's not that bad,\\n0....\n",
       "4  SBC023.trn  ﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(txt_dict.items()))\n",
    "df.columns = [\"Filename\", \"Text\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc7e78",
   "metadata": {},
   "source": [
    "## Pre-tokenizing\n",
    "Before tokenizing, I've removed a few choice chars that are usually placed in the middle of words in the transcripts. In doing this, the tokenizer can keep the full words together rather than breaking them up into small clusters of letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49fd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df.Text.map(lambda x: x.replace('=',''))\n",
    "df[\"Text\"] = df.Text.map(lambda x: x.replace('[',''))\n",
    "df[\"Text\"] = df.Text.map(lambda x: x.replace(']',''))\n",
    "df[\"Text\"] = df.Text.map(lambda x: x.replace(r'\\d',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b36cbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBC034.trn</td>\n",
       "      <td>﻿0.000\\t4.475\\t&gt;ENV:\\t((DOOR_OPENING_AND_CLOSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBC008.trn</td>\n",
       "      <td>﻿0.00 3.40\\t&gt;ENV:   \\t((DOOR_OPENS)) &lt;&lt;TALK\\n3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBC009.trn</td>\n",
       "      <td>﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBC035.trn</td>\n",
       "      <td>﻿0.000\\t1.020\\tPATTY:\\tIt's not that bad,\\n0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBC023.trn</td>\n",
       "      <td>﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                                               Text\n",
       "0  SBC034.trn  ﻿0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSI...\n",
       "1  SBC008.trn  ﻿0.00 3.40\\t>ENV:   \\t((DOOR_OPENS)) <<TALK\\n3...\n",
       "2  SBC009.trn  ﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...\n",
       "3  SBC035.trn  ﻿0.000\\t1.020\\tPATTY:\\tIt's not that bad,\\n0.0...\n",
       "4  SBC023.trn  ﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223c876",
   "metadata": {},
   "source": [
    "## Tokenize and clean up data\n",
    "1) NLTK tokenize text\n",
    "2) Get rid of chars that are non-alphabetic, all upper case, and in `to_remove` (which includes all the alphabetic chars that aren't actual words – found in `removals`)\n",
    "3) Re-order rows\n",
    "### 1. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6d5ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBC034.trn</td>\n",
       "      <td>﻿0.000\\t4.475\\t&gt;ENV:\\t((DOOR_OPENING_AND_CLOSI...</td>\n",
       "      <td>[﻿0.000, 4.475, &gt;, ENV, :, (, (, DOOR_OPENING_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBC008.trn</td>\n",
       "      <td>﻿0.00 3.40\\t&gt;ENV:   \\t((DOOR_OPENS)) &lt;&lt;TALK\\n3...</td>\n",
       "      <td>[﻿0.00, 3.40, &gt;, ENV, :, (, (, DOOR_OPENS, ), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBC009.trn</td>\n",
       "      <td>﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...</td>\n",
       "      <td>[﻿0.00, 13.16, NATHAN, :, ..., (, H, ), Am, I,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBC035.trn</td>\n",
       "      <td>﻿0.000\\t1.020\\tPATTY:\\tIt's not that bad,\\n0.0...</td>\n",
       "      <td>[﻿0.000, 1.020, PATTY, :, It, 's, not, that, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBC023.trn</td>\n",
       "      <td>﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though...</td>\n",
       "      <td>[﻿1.506, 4.132, EVELYN, :, Another, thing, I, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                                               Text  \\\n",
       "0  SBC034.trn  ﻿0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSI...   \n",
       "1  SBC008.trn  ﻿0.00 3.40\\t>ENV:   \\t((DOOR_OPENS)) <<TALK\\n3...   \n",
       "2  SBC009.trn  ﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...   \n",
       "3  SBC035.trn  ﻿0.000\\t1.020\\tPATTY:\\tIt's not that bad,\\n0.0...   \n",
       "4  SBC023.trn  ﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [﻿0.000, 4.475, >, ENV, :, (, (, DOOR_OPENING_...  \n",
       "1  [﻿0.00, 3.40, >, ENV, :, (, (, DOOR_OPENS, ), ...  \n",
       "2  [﻿0.00, 13.16, NATHAN, :, ..., (, H, ), Am, I,...  \n",
       "3  [﻿0.000, 1.020, PATTY, :, It, 's, not, that, b...  \n",
       "4  [﻿1.506, 4.132, EVELYN, :, Another, thing, I, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tokens'] = df.Text.map(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353ad7a",
   "metadata": {},
   "source": [
    "### The specific things we want to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551b2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/mayaasher/data_science/metadata/annotations.txt\", \"r\")\n",
    "removals = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33466c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santa Barbara Corpus of Spoken American English Part-II\n",
      "\n",
      "  \n",
      "\n",
      "Units \n",
      "    Intonation Unit\t\t\tRETURN \n",
      "    Truncated intonation unit\t\t-- \n",
      "    word\t\t\t\tSPACE \n",
      "    truncated word\t\t\t_ \n",
      "\n",
      "Speakers \n",
      "    Speaker identity/turn start\t\t: \n",
      "    Speech overlap\t\t\t[ ] \n",
      "\n",
      "Transitional Continuity \n",
      "    Final\t\t\t\t. \n",
      "    Continuing\t\t\t\t, \n",
      "    Appeal\t\t\t\t? \n",
      "\n",
      "Terminal Pitch Direction \n",
      "    Fall\t\t\t\t\\ \n",
      "    Rise\t\t\t\t/ \n",
      "    Level\t\t\t\t- \n",
      "\n",
      "Accent and Lengthening \n",
      "    Primary accent\t\t\t^ \n",
      "    Secondary accent\t\t\t' \n",
      "    Booster\t\t\t\t! \n",
      "    Lengthening\t\t\t\t= \n",
      "\n",
      "Tone \n",
      "    Fall\t\t\t\t\\ \n",
      "    Rise\t\t\t\t/ \n",
      "    Fall-rise\t\t\t\t\\/ \n",
      "    Rise-fall\t\t\t\t/\\ \n",
      "    Level\t\t\t\t- \n",
      "\n",
      "Pause \n",
      "    Long\t\t\t\t...(N) \n",
      "    Medium\t\t\t\t... \n",
      "    Short\t\t\t\t.. \n",
      "    Latching\t\t\t\t(0) \n",
      "\n",
      "Vocal Noises \n",
      "    Vocal noises\t\t\t( ) \n",
      "    Inhalation\t\t\t\t(H) \n",
      "    Exhalation\t\t\t\t(Hx) \n",
      "    Glottal stop\t\t\t% \n",
      "    Laughter\t\t\t\t@ \n",
      "\n",
      "Quality \n",
      "    Quality\t\t\t\t<Y  Y> \n",
      "    Laugh quality\t\t\t<@  @> \n",
      "    Quotation quality\t\t\t<Q  Q> \n",
      "    Multiple quality features\t\t<Y  <Z  Z>  Y> \n",
      "\n",
      "Phonetics \n",
      "    Phonetic transcription\t\t(/  /) \n",
      "\n",
      "Transcriber's Perspective \n",
      "    Researcher's comments\t\t((  )) \n",
      "    Uncertain hearing\t\t\t<X  X> \n",
      "    Indecipherable syllable\t\tX \n",
      "\n",
      "Specialized notation \n",
      "    Duration\t\t\t\t(N) \n",
      "    Intonation unit continued\t\t& \n",
      "    Intonation subunit boundary\t\t| \n",
      "    Embedded intonation unit\t\t<| |> \n",
      "    Reset \n",
      "    False start\t\t\t\t< >\n",
      "    Codeswitching\t\t\t<L2 L2> \n",
      "\n",
      "Non-transcription Lines \n",
      "    Comment\t\t\t\t$\n",
      "    Interlinear gloss\t\t\t$G\n",
      "\n",
      "Reserved Symbols \n",
      "    Phonemic/orthographic\t\t, \n",
      "    Morphosyntactic coding\t\t = * # { } \n",
      "    User-definable\t\t\t \" ~ ; \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(removals) # the specific chars we want to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccbed0",
   "metadata": {},
   "source": [
    "### 2. The removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca88712",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['N', 'H', 'Hx', 'Y', 'Q', 'Z', 'X', 'L2', 'G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f58156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(ls):\n",
    "    return [item.lower() for item in ls if item.isalpha() and not item.isupper() and item not in to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f3848ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBC034.trn</td>\n",
       "      <td>﻿0.000\\t4.475\\t&gt;ENV:\\t((DOOR_OPENING_AND_CLOSI...</td>\n",
       "      <td>[﻿0.000, 4.475, &gt;, ENV, :, (, (, DOOR_OPENING_...</td>\n",
       "      <td>[hi, sweetie, hey, sweetie, frumptions, this, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBC008.trn</td>\n",
       "      <td>﻿0.00 3.40\\t&gt;ENV:   \\t((DOOR_OPENS)) &lt;&lt;TALK\\n3...</td>\n",
       "      <td>[﻿0.00, 3.40, &gt;, ENV, :, (, (, DOOR_OPENS, ), ...</td>\n",
       "      <td>[okay, um, the, the, way, that, your, testimon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBC009.trn</td>\n",
       "      <td>﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...</td>\n",
       "      <td>[﻿0.00, 13.16, NATHAN, :, ..., (, H, ), Am, I,...</td>\n",
       "      <td>[am, doing, that, right, so, far, mhm, all, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBC035.trn</td>\n",
       "      <td>﻿0.000\\t1.020\\tPATTY:\\tIt's not that bad,\\n0.0...</td>\n",
       "      <td>[﻿0.000, 1.020, PATTY, :, It, 's, not, that, b...</td>\n",
       "      <td>[it, not, that, bad, something, else, or, do, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBC023.trn</td>\n",
       "      <td>﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though...</td>\n",
       "      <td>[﻿1.506, 4.132, EVELYN, :, Another, thing, I, ...</td>\n",
       "      <td>[another, thing, thought, was, interesting, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                                               Text  \\\n",
       "0  SBC034.trn  ﻿0.000\\t4.475\\t>ENV:\\t((DOOR_OPENING_AND_CLOSI...   \n",
       "1  SBC008.trn  ﻿0.00 3.40\\t>ENV:   \\t((DOOR_OPENS)) <<TALK\\n3...   \n",
       "2  SBC009.trn  ﻿0.00 13.16\\tNATHAN: \\t... (H) Am I doing that...   \n",
       "3  SBC035.trn  ﻿0.000\\t1.020\\tPATTY:\\tIt's not that bad,\\n0.0...   \n",
       "4  SBC023.trn  ﻿1.506\\t4.132\\tEVELYN:\\tAnother thing I though...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [﻿0.000, 4.475, >, ENV, :, (, (, DOOR_OPENING_...   \n",
       "1  [﻿0.00, 3.40, >, ENV, :, (, (, DOOR_OPENS, ), ...   \n",
       "2  [﻿0.00, 13.16, NATHAN, :, ..., (, H, ), Am, I,...   \n",
       "3  [﻿0.000, 1.020, PATTY, :, It, 's, not, that, b...   \n",
       "4  [﻿1.506, 4.132, EVELYN, :, Another, thing, I, ...   \n",
       "\n",
       "                                               Clean  \n",
       "0  [hi, sweetie, hey, sweetie, frumptions, this, ...  \n",
       "1  [okay, um, the, the, way, that, your, testimon...  \n",
       "2  [am, doing, that, right, so, far, mhm, all, th...  \n",
       "3  [it, not, that, bad, something, else, or, do, ...  \n",
       "4  [another, thing, thought, was, interesting, wa...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Clean\"] = df.Tokens.apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc70bd",
   "metadata": {},
   "source": [
    "### 3. Re-ordering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa2955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SBC001.trn</td>\n",
       "      <td>﻿0.00 9.21\\tLENORE: \\t... So you don't need to...</td>\n",
       "      <td>[﻿0.00, 9.21, LENORE, :, ..., So, you, do, n't...</td>\n",
       "      <td>[so, you, do, need, to, go, borrow, equipment,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SBC002.trn</td>\n",
       "      <td>﻿0.00 6.52\\tJAMIE:  \\tHow can you teach a thre...</td>\n",
       "      <td>[﻿0.00, 6.52, JAMIE, :, How, can, you, teach, ...</td>\n",
       "      <td>[how, can, you, teach, a, to, tap, ca, imagine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SBC003.trn</td>\n",
       "      <td>﻿0.00 1.01\\tMARILYN: \\t(Hx) Okay.\\n0.30 1.65\\t...</td>\n",
       "      <td>[﻿0.00, 1.01, MARILYN, :, (, Hx, ), Okay, ., 0...</td>\n",
       "      <td>[okay, do, you, have, a, particular, um, use, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SBC004.trn</td>\n",
       "      <td>﻿0.00 1.07\\tPAM:    \\t.. Juice 2anybody2?\\n0.4...</td>\n",
       "      <td>[﻿0.00, 1.07, PAM, :, .., Juice, 2anybody2, ?,...</td>\n",
       "      <td>[juice, like, for, a, little, while, you, go, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SBC005.trn</td>\n",
       "      <td>﻿0.00 3.46\\tDARRYL: \\tBut,\\n3.46 6.71\\t       ...</td>\n",
       "      <td>[﻿0.00, 3.46, DARRYL, :, But, ,, 3.46, 6.71, ....</td>\n",
       "      <td>[but, but, to, try, and, and, talk, me, out, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Filename                                               Text  \\\n",
       "29  SBC001.trn  ﻿0.00 9.21\\tLENORE: \\t... So you don't need to...   \n",
       "32  SBC002.trn  ﻿0.00 6.52\\tJAMIE:  \\tHow can you teach a thre...   \n",
       "35  SBC003.trn  ﻿0.00 1.01\\tMARILYN: \\t(Hx) Okay.\\n0.30 1.65\\t...   \n",
       "40  SBC004.trn  ﻿0.00 1.07\\tPAM:    \\t.. Juice 2anybody2?\\n0.4...   \n",
       "41  SBC005.trn  ﻿0.00 3.46\\tDARRYL: \\tBut,\\n3.46 6.71\\t       ...   \n",
       "\n",
       "                                               Tokens  \\\n",
       "29  [﻿0.00, 9.21, LENORE, :, ..., So, you, do, n't...   \n",
       "32  [﻿0.00, 6.52, JAMIE, :, How, can, you, teach, ...   \n",
       "35  [﻿0.00, 1.01, MARILYN, :, (, Hx, ), Okay, ., 0...   \n",
       "40  [﻿0.00, 1.07, PAM, :, .., Juice, 2anybody2, ?,...   \n",
       "41  [﻿0.00, 3.46, DARRYL, :, But, ,, 3.46, 6.71, ....   \n",
       "\n",
       "                                                Clean  \n",
       "29  [so, you, do, need, to, go, borrow, equipment,...  \n",
       "32  [how, can, you, teach, a, to, tap, ca, imagine...  \n",
       "35  [okay, do, you, have, a, particular, um, use, ...  \n",
       "40  [juice, like, for, a, little, while, you, go, ...  \n",
       "41  [but, but, to, try, and, and, talk, me, out, o...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorts filenames for convenience\n",
    "df = df.sort_values(\n",
    "    by=\"Filename\",\n",
    "    key=lambda x: np.argsort(index_natsorted(df[\"Filename\"])))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8243483",
   "metadata": {},
   "source": [
    "## Basic Stats\n",
    "In this section, I've added lots of columns with token stats, including token count, TTR, and average word length. Since this is spontaneous speech, there aren't necessarily sentences, so I didn't analyze that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "503ae83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SBC001.trn</td>\n",
       "      <td>﻿0.00 9.21\\tLENORE: \\t... So you don't need to...</td>\n",
       "      <td>[﻿0.00, 9.21, LENORE, :, ..., So, you, do, n't...</td>\n",
       "      <td>[so, you, do, need, to, go, borrow, equipment,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filename                                               Text  \\\n",
       "count           43                                                 43   \n",
       "unique          43                                                 43   \n",
       "top     SBC001.trn  ﻿0.00 9.21\\tLENORE: \\t... So you don't need to...   \n",
       "freq             1                                                  1   \n",
       "\n",
       "                                                   Tokens  \\\n",
       "count                                                  43   \n",
       "unique                                                 43   \n",
       "top     [﻿0.00, 9.21, LENORE, :, ..., So, you, do, n't...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                    Clean  \n",
       "count                                                  43  \n",
       "unique                                                 43  \n",
       "top     [so, you, do, need, to, go, borrow, equipment,...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc2738e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ttr(toks):\n",
    "    lower = [w.lower() for w in toks]\n",
    "    return len(set(lower))/len(lower)\n",
    "def get_avg_word_length(toks):\n",
    "    toklen_nosym = [len(w) for w in toks if w.isalnum()]\n",
    "    return np.mean(toklen_nosym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce99efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Token_count'] = df.Clean.map(len)\n",
    "df['TTR'] = df.Clean.map(get_ttr)\n",
    "df['Avg_word_len'] = df.Clean.map(get_avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f48fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SBC001.trn</td>\n",
       "      <td>﻿0.00 9.21\\tLENORE: \\t... So you don't need to...</td>\n",
       "      <td>[﻿0.00, 9.21, LENORE, :, ..., So, you, do, n't...</td>\n",
       "      <td>[so, you, do, need, to, go, borrow, equipment,...</td>\n",
       "      <td>4766</td>\n",
       "      <td>0.143097</td>\n",
       "      <td>3.777801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SBC002.trn</td>\n",
       "      <td>﻿0.00 6.52\\tJAMIE:  \\tHow can you teach a thre...</td>\n",
       "      <td>[﻿0.00, 6.52, JAMIE, :, How, can, you, teach, ...</td>\n",
       "      <td>[how, can, you, teach, a, to, tap, ca, imagine...</td>\n",
       "      <td>4173</td>\n",
       "      <td>0.187395</td>\n",
       "      <td>3.979631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SBC003.trn</td>\n",
       "      <td>﻿0.00 1.01\\tMARILYN: \\t(Hx) Okay.\\n0.30 1.65\\t...</td>\n",
       "      <td>[﻿0.00, 1.01, MARILYN, :, (, Hx, ), Okay, ., 0...</td>\n",
       "      <td>[okay, do, you, have, a, particular, um, use, ...</td>\n",
       "      <td>4233</td>\n",
       "      <td>0.208835</td>\n",
       "      <td>3.965509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SBC004.trn</td>\n",
       "      <td>﻿0.00 1.07\\tPAM:    \\t.. Juice 2anybody2?\\n0.4...</td>\n",
       "      <td>[﻿0.00, 1.07, PAM, :, .., Juice, 2anybody2, ?,...</td>\n",
       "      <td>[juice, like, for, a, little, while, you, go, ...</td>\n",
       "      <td>3788</td>\n",
       "      <td>0.195354</td>\n",
       "      <td>3.858237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SBC005.trn</td>\n",
       "      <td>﻿0.00 3.46\\tDARRYL: \\tBut,\\n3.46 6.71\\t       ...</td>\n",
       "      <td>[﻿0.00, 3.46, DARRYL, :, But, ,, 3.46, 6.71, ....</td>\n",
       "      <td>[but, but, to, try, and, and, talk, me, out, o...</td>\n",
       "      <td>2575</td>\n",
       "      <td>0.222913</td>\n",
       "      <td>3.987573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Filename                                               Text  \\\n",
       "29  SBC001.trn  ﻿0.00 9.21\\tLENORE: \\t... So you don't need to...   \n",
       "32  SBC002.trn  ﻿0.00 6.52\\tJAMIE:  \\tHow can you teach a thre...   \n",
       "35  SBC003.trn  ﻿0.00 1.01\\tMARILYN: \\t(Hx) Okay.\\n0.30 1.65\\t...   \n",
       "40  SBC004.trn  ﻿0.00 1.07\\tPAM:    \\t.. Juice 2anybody2?\\n0.4...   \n",
       "41  SBC005.trn  ﻿0.00 3.46\\tDARRYL: \\tBut,\\n3.46 6.71\\t       ...   \n",
       "\n",
       "                                               Tokens  \\\n",
       "29  [﻿0.00, 9.21, LENORE, :, ..., So, you, do, n't...   \n",
       "32  [﻿0.00, 6.52, JAMIE, :, How, can, you, teach, ...   \n",
       "35  [﻿0.00, 1.01, MARILYN, :, (, Hx, ), Okay, ., 0...   \n",
       "40  [﻿0.00, 1.07, PAM, :, .., Juice, 2anybody2, ?,...   \n",
       "41  [﻿0.00, 3.46, DARRYL, :, But, ,, 3.46, 6.71, ....   \n",
       "\n",
       "                                                Clean  Token_count       TTR  \\\n",
       "29  [so, you, do, need, to, go, borrow, equipment,...         4766  0.143097   \n",
       "32  [how, can, you, teach, a, to, tap, ca, imagine...         4173  0.187395   \n",
       "35  [okay, do, you, have, a, particular, um, use, ...         4233  0.208835   \n",
       "40  [juice, like, for, a, little, while, you, go, ...         3788  0.195354   \n",
       "41  [but, but, to, try, and, and, talk, me, out, o...         2575  0.222913   \n",
       "\n",
       "    Avg_word_len  \n",
       "29      3.777801  \n",
       "32      3.979631  \n",
       "35      3.965509  \n",
       "40      3.858237  \n",
       "41      3.987573  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf895eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3780.720930</td>\n",
       "      <td>0.189910</td>\n",
       "      <td>3.832377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1142.478995</td>\n",
       "      <td>0.029888</td>\n",
       "      <td>0.115208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1673.000000</td>\n",
       "      <td>0.134072</td>\n",
       "      <td>3.602993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2777.000000</td>\n",
       "      <td>0.170342</td>\n",
       "      <td>3.758178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3847.000000</td>\n",
       "      <td>0.187395</td>\n",
       "      <td>3.816598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4520.000000</td>\n",
       "      <td>0.209356</td>\n",
       "      <td>3.870632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6035.000000</td>\n",
       "      <td>0.253437</td>\n",
       "      <td>4.149758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Token_count        TTR  Avg_word_len\n",
       "count    43.000000  43.000000     43.000000\n",
       "mean   3780.720930   0.189910      3.832377\n",
       "std    1142.478995   0.029888      0.115208\n",
       "min    1673.000000   0.134072      3.602993\n",
       "25%    2777.000000   0.170342      3.758178\n",
       "50%    3847.000000   0.187395      3.816598\n",
       "75%    4520.000000   0.209356      3.870632\n",
       "max    6035.000000   0.253437      4.149758"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18125f08",
   "metadata": {},
   "source": [
    "The average word length overall was about 4 letters which feels oddly small. Perhaps since it's spontaneous speech people speak in shorter words as opposed to written text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e0ade0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  5.,  6., 10., 11.,  1.,  3.,  4.,  1.,  1.]), array([3.60299296, 3.65766951, 3.71234606, 3.76702261, 3.82169916,\n",
       "       3.87637571, 3.93105226, 3.98572881, 4.04040535, 4.0950819 ,\n",
       "       4.14975845]), <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(df.Avg_word_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
