{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d52c9b",
   "metadata": {},
   "source": [
    "Maya Asher, 4/17/24\n",
    "# Analyzing the SBCSAE\n",
    "**NEW CONTINUING**\n",
    "\n",
    "Using the processed data (which can be found [here](https://github.com/Data-Science-for-Linguists-2024/Stance-Taking-in-Spontaneous-Speech/blob/main/reprocessing_sbcsae.ipynb)) we can begin our stance taking anaylsis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a116a05",
   "metadata": {},
   "source": [
    "## Object of analysis\n",
    "**TL;DR**: This analysis will focus on lexical items that vary in their levels of investment (*like* vs. *love* and *don't like* vs. *hate*). This is based on a three dimensional model of analyzing stance and stanctaking explained in Kiesling (2022).\n",
    "### Background\n",
    "As Dr. Scott Kiesling discusses in his paper \"Stance and Stancetaking\" (2022), stance is how people position themselves in conversations and it can be analyzed using a three-dimensional model that encompasses **evaluation**, **alignment**, and **investment**. In a simple conversation, animator A evaluates an object, prompting animator B to also evaluate that object, resulting in an alignment or disalignment between the two interlocutors. Investment is the extent to which each person commits to their evaluation. \n",
    "\n",
    "So, for example, if I were to say \"I really love data science,\" I am indexing a large amount of investment to my evaluation of data science. Then, if my interlocutor were to respond, \"I kind of like data science,\" we are somewhat aligning by speaking of data science in a positive light, but they are indexing less investment in their evaluation than I am. \n",
    "\n",
    "In the example above, investment was indexed through the lexical items *really love* and *kind of like*, but an animator's level of investment can also be indicated through epistemicity and evidentiality.\n",
    "\n",
    "In this three-dimensional model of analysis, there are also three participant roles: the **author** who composes the essential text, the **animator** who produces the speech, and the **principal** who takes responsibility for the utterance. This idea will be explored later on in the analysis.\n",
    "### Current investigation\n",
    "With the idea of investment established, my focus for this project will be to identify lexical items that index varying levels of investment and analyze their contexts and frequencies, producing both qualitative and quantitative results that can be compared to one another. \n",
    "\n",
    "Specifically, I will look at *like* vs. *love* and *don't like* vs. *hate*, both varying in levels of investment but the former being positive and the latter being negative. To do this, we will unpickle our dictionaries of data frames and begin our search for our target words.\n",
    "\n",
    "### Citation\n",
    "Kiesling, S. F. (2022). Stance and Stancetaking. *Annual Review of Linguistics*, 8, 409-426. https://doi.org/10.1146/annurev-linguistics-031120-121256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2cc9f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db968ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3032e",
   "metadata": {},
   "source": [
    "## Unpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b36f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('all_dfs.pkl', 'rb')\n",
    "dfs = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a850b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df2col.pkl', 'rb')\n",
    "df2c = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ab1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df3col.pkl', 'rb')\n",
    "df3c = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34b7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df4col.pkl', 'rb')\n",
    "df4c = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64b38ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SBC001.trn', 'SBC002.trn', 'SBC003.trn', 'SBC004.trn', 'SBC005.trn', 'SBC006.trn', 'SBC007.trn', 'SBC008.trn', 'SBC009.trn', 'SBC010.trn', 'SBC011.trn', 'SBC013.trn']) dict_keys(['SBC014.trn']) dict_keys(['SBC015.trn', 'SBC016.trn', 'SBC017.trn', 'SBC018.trn', 'SBC019.trn', 'SBC022.trn', 'SBC023.trn', 'SBC024.trn', 'SBC029.trn', 'SBC031.trn', 'SBC032.trn', 'SBC033.trn', 'SBC034.trn', 'SBC035.trn', 'SBC036.trn', 'SBC037.trn', 'SBC042.trn', 'SBC043.trn', 'SBC044.trn', 'SBC045.trn', 'SBC047.trn', 'SBC048.trn', 'SBC049.trn', 'SBC050.trn', 'SBC051.trn', 'SBC056.trn', 'SBC057.trn', 'SBC058.trn', 'SBC059.trn', 'SBC060.trn'])\n"
     ]
    }
   ],
   "source": [
    "# looks good\n",
    "print(df3c.keys(), df2c.keys(), df4c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf9ec64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# got them all!\n",
    "len(df4c) + len(df3c) + len(df2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41ee589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfect!\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c4804",
   "metadata": {},
   "source": [
    "## Investigate text\n",
    "Since we labeled each dictionary's df columns the same (at least for `text`), we can use the dictionary that has ALL of the dfs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4925c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00 2.53  FRED:</td>\n",
       "      <td>... Okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.53 4.73</td>\n",
       "      <td>One= large loan (Hx),</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.73 6.23</td>\n",
       "      <td>... renewed (Hx),</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.23 8.08</td>\n",
       "      <td>... a hundred ninety-seven= .. thousand,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.08 9.23</td>\n",
       "      <td>a hundred eighty dollars.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          time_speaker                                      text\n",
       "0  0.00 2.53  FRED:                                    ... Okay.\n",
       "1   2.53 4.73                              One= large loan (Hx),\n",
       "2   4.73 6.23                                  ... renewed (Hx),\n",
       "3   6.23 8.08           ... a hundred ninety-seven= .. thousand,\n",
       "4   8.08 9.23                          a hundred eighty dollars."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"SBC014.trn\"].head() # 2 col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1beb36fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00 1.24</td>\n",
       "      <td>KEVIN:</td>\n",
       "      <td>Is that just [carbonated water]?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45 1.24</td>\n",
       "      <td>WENDY:</td>\n",
       "      <td>[No thank you].</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.24 1.50</td>\n",
       "      <td></td>\n",
       "      <td>[2No,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.24 3.38</td>\n",
       "      <td>KEN:</td>\n",
       "      <td>[2(H) No this is2] crea=m [3soda.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.50 2.36</td>\n",
       "      <td>WENDY:</td>\n",
       "      <td>It's cream soda2].</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time   speaker                               text\n",
       "0  0.00 1.24  KEVIN:     Is that just [carbonated water]?\n",
       "1  0.45 1.24  WENDY:                      [No thank you].\n",
       "2  1.24 1.50                                        [2No,\n",
       "3  1.24 3.38  KEN:      [2(H) No this is2] crea=m [3soda.\n",
       "4  1.50 2.36  WENDY:                   It's cream soda2]."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"SBC013.trn\"].head() # 3 col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81765a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.660</td>\n",
       "      <td>2.805</td>\n",
       "      <td>JOANNE:</td>\n",
       "      <td>But,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.805</td>\n",
       "      <td>4.685</td>\n",
       "      <td></td>\n",
       "      <td>so these slides &lt;X should X&gt; be real interesting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.140</td>\n",
       "      <td>6.325</td>\n",
       "      <td>KEN:</td>\n",
       "      <td>... Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.325</td>\n",
       "      <td>7.710</td>\n",
       "      <td></td>\n",
       "      <td>I think it'll be real interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.710</td>\n",
       "      <td>8.535</td>\n",
       "      <td></td>\n",
       "      <td>I think it'll be a real,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_start  time_end  speaker  \\\n",
       "0       2.660     2.805  JOANNE:   \n",
       "1       2.805     4.685            \n",
       "2       6.140     6.325     KEN:   \n",
       "3       6.325     7.710            \n",
       "4       7.710     8.535            \n",
       "\n",
       "                                                text  \n",
       "0                                               But,  \n",
       "1  so these slides <X should X> be real interesting.  \n",
       "2                                          ... Yeah.  \n",
       "3                  I think it'll be real interesting  \n",
       "4                           I think it'll be a real,  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"SBC015.trn\"].head() # 4 col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45deba",
   "metadata": {},
   "source": [
    "## Extract lexical items\n",
    "The two lexical items we want are 'like' and 'love'. We will create a dictionary for each word with the key being the file name (ex: `SBC001.trn`) and the value being a list of tuples that look like (row number, 'like' in context). Thankfully, we can work with `dfs` because all the `text` columns are labeled as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cd56d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = {}\n",
    "loves = {}\n",
    "\n",
    "# iterate through each df in the dict\n",
    "for df_name, df in dfs.items():\n",
    "    \n",
    "    # extract rows where the target word is found in the text column\n",
    "    like_rows = df[df['text'].str.contains(r'\\blike\\b', case=False, regex=True)]\n",
    "    love_rows = df[df['text'].str.contains(r'\\blove\\b', case=False, regex=True)]\n",
    "    \n",
    "    # list of tuples containing (row #, text) for each occurrence\n",
    "    like_occurrences = [(index, row['text']) for index, row in like_rows.iterrows()]\n",
    "    love_occurrences = [(index, row['text']) for index, row in love_rows.iterrows()]\n",
    "   \n",
    "    # save the occurrences in the dict\n",
    "    likes[df_name] = like_occurrences\n",
    "    loves[df_name] = love_occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c8495",
   "metadata": {},
   "source": [
    "I can't flash `likes` because it is too large, but the other dictionaries relatively sparse. Hopefully there will still be enough qualitative information that can be extracted, but I worry that there will be no sufficient quantitative data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa2bca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SBC001.trn': [], 'SBC002.trn': [], 'SBC003.trn': [(1008, \"I'd love to do gray water,\"), (1262, '... Oh I love green beans.')], 'SBC004.trn': [(68, '[2They love to --'), (70, '.. They love to point it out when <X I X>2] --'), (163, '                            [3I love it @>3].')], 'SBC005.trn': [(427, '... Love?'), (429, '[<VOX Love]?'), (431, '(H) Could [2I2] love you?'), (435, \"(H) Could I love you while I'm here VOX>?\"), (503, '... love fills the stockings.'), (515, 'adults around who love you.')], 'SBC006.trn': [], 'SBC007.trn': [], 'SBC008.trn': [], 'SBC009.trn': [], 'SBC010.trn': [], 'SBC011.trn': [(80, '... and I love you,')], 'SBC013.trn': [(1859, '... <VOX True love VOX>.'), (1961, '    [I love] new windshield wipers.'), (2152, '.. Oh I love [!Edna].')], 'SBC014.trn': [(981, '.. I love ... expansions of business.')], 'SBC015.trn': [(236, 'I would love --'), (237, '.. I would love to go=.'), (684, '             [6Cats love those6].'), (1308, '.. I love the little fl- --'), (1467, '[3they love to eat3],'), (1469, 'they love --'), (1475, \"                                    [3I'd love to see it3].\"), (1477, \"I'd love to see him chase and eat [4up a goldfish,\"), (1778, 'she said she really would[love to see the turtles eat a gold]fish,')], 'SBC016.trn': [(1000, '.. and [they love] it.')], 'SBC017.trn': [(20, 'creative people generally] do what they love [2to do2].')], 'SBC018.trn': [], 'SBC019.trn': [], 'SBC022.trn': [], 'SBC023.trn': [(505, \".. (H) the brother of the person that she's in [love with] marries [2her2],\")], 'SBC024.trn': [], 'SBC029.trn': [], 'SBC031.trn': [(567, 'I love hot tea.')], 'SBC032.trn': [], 'SBC033.trn': [], 'SBC034.trn': [(523, '... <F Reclining love seat F>.')], 'SBC035.trn': [(247, 'I fell in love with that school right [away but],'), (892, \".. that's where uh the Love Connection is [2<X though X>2].\")], 'SBC036.trn': [], 'SBC037.trn': [], 'SBC042.trn': [(162, '.. <X I .. love your jeans X>.')], 'SBC043.trn': [], 'SBC044.trn': [(203, 'because I want him to know that I do love him.'), (965, 'I was in love with ~Darren.'), (1068, \"(H) he loves her but he's not in love with her.\"), (1074, 'you can love a person,'), (1075, \".. but .. you're not [in love] with them,\"), (1084, '.. to love someone and,'), (1085, 'when you tell someone you love them,'), (1087, 'what love is all about.'), (1098, \".. (H) I wasn't really in love with his looks,\"), (1219, '[How could he] really love you though,'), (1247, '... I st- I love him,'), (1289, 'I love ~Lauren,'), (1301, '(H) and he says I really love ~Lauren,')], 'SBC045.trn': [(303, '<YWN Oh I love that YWN>.'), (1010, '.. the master fi- .. falls in love with him,')], 'SBC047.trn': [(334, 'that we still have a lot of= love for each other,'), (340, 'a=nd I still love her=,'), (446, 'I really did love her,')], 'SBC048.trn': [(182, 'I love [it].')], 'SBC049.trn': [(811, '... Who would love to @have their house done,')], 'SBC050.trn': [(27, '.. I love this bread.'), (37, '<@ I love it @>.'), (96, '... I love em though.'), (628, '.. Men love that stuff.')], 'SBC051.trn': [(428, 'I love it.'), (872, '[3I love this3].'), (1116, '[Cause I] fell in love with the re=[2=d2],'), (1181, \"[Don't you love it out here,\"), (1182, \"don't you love it]?\"), (1498, '[2I love theater2].')], 'SBC056.trn': [(917, '(H) But [then he fell in love with her and it was --')], 'SBC057.trn': [(172, 'I love it,')], 'SBC058.trn': [(244, '[Y]eah I used to love Ouija boards when I was a little girl.')], 'SBC059.trn': [(1335, 'Oh I [love <X toffee X>.')], 'SBC060.trn': [(516, 'love him.')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020797d",
   "metadata": {},
   "source": [
    "## Extract discourse markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f7da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = {}\n",
    "fines = {}\n",
    "goods = {}\n",
    "greats = {}\n",
    "rights = {}\n",
    "imeans = {}\n",
    "\n",
    "# iterate through each df in the dict\n",
    "for df_name, df in dfs.items():\n",
    "    \n",
    "    # extract rows where the target word is found in the text column\n",
    "    well_rows = df[df['text'].str.contains(r'\\bwell\\b', case=False, regex=True)]\n",
    "    fine_rows = df[df['text'].str.contains(r'\\bfine\\b', case=False, regex=True)]\n",
    "    good_rows = df[df['text'].str.contains(r'\\bgood\\b', case=False, regex=True)]\n",
    "    great_rows = df[df['text'].str.contains(r'\\bgreat\\b', case=False, regex=True)]\n",
    "    right_rows = df[df['text'].str.contains(r'\\bright\\b', case=False, regex=True)]\n",
    "    imean_rows = df[df['text'].str.contains(r'\\bI\\smean\\b', case=False, regex=True)]\n",
    "\n",
    "    # list of tuples containing (row #, text) for each occurrence\n",
    "    well_occurrences = [(index, row['text']) for index, row in well_rows.iterrows()]\n",
    "    fine_occurrences = [(index, row['text']) for index, row in fine_rows.iterrows()]\n",
    "    good_occurrences = [(index, row['text']) for index, row in good_rows.iterrows()]\n",
    "    great_occurrences = [(index, row['text']) for index, row in great_rows.iterrows()]\n",
    "    right_occurrences = [(index, row['text']) for index, row in right_rows.iterrows()]\n",
    "    imean_occurrences = [(index, row['text']) for index, row in imean_rows.iterrows()]\n",
    "\n",
    "    # save the occurrences in the dict\n",
    "    wells[df_name] = well_occurrences\n",
    "    fines[df_name] = fine_occurrences\n",
    "    goods[df_name] = good_occurrences\n",
    "    greats[df_name] = great_occurrences\n",
    "    rights[df_name] = right_occurrences\n",
    "    imeans[df_name] = imean_occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab4ca4",
   "metadata": {},
   "source": [
    "## Trying out analysis with only \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd7907ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, \"(H) ... and I'm not as good,\"), (40, \".. (H)= and I'm not (Hx) ... that good or,\"), (496, \"cause you don't want to .. cripple up a .. (H) really good horse,\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goods[\"SBC001.trn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3299674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SBC001.trn': [24, 40, 496], 'SBC002.trn': [236, 490, 874, 940, 1407], 'SBC003.trn': [61, 62, 111, 410, 754, 765, 768, 932, 935, 947, 1003, 1098, 1263, 1430, 1433, 1453, 1476], 'SBC004.trn': [12, 25, 28, 330, 331, 610, 819, 852, 864], 'SBC005.trn': [65], 'SBC006.trn': [179, 542, 721, 744, 1167, 1206, 1226, 1410, 1746], 'SBC007.trn': [93, 578], 'SBC008.trn': [1029, 1488], 'SBC009.trn': [688], 'SBC010.trn': [766, 993], 'SBC011.trn': [171, 197, 198, 384, 602, 652, 755, 849], 'SBC013.trn': [247, 339, 382, 786, 787, 854, 865, 968, 1232, 1430, 1716, 1743, 1760, 1761, 1787, 1789, 1813, 1821, 1994, 1996, 2207, 2234], 'SBC014.trn': [493, 617, 641, 657, 843], 'SBC015.trn': [5, 692, 709, 764], 'SBC016.trn': [3, 13, 81, 386, 388, 523, 617, 694, 1070, 1135, 1148, 1417, 1485, 1489, 1490, 1506, 1507], 'SBC017.trn': [], 'SBC018.trn': [4, 106, 163, 176], 'SBC019.trn': [96, 247, 251, 292, 296, 302, 402, 403, 734, 1015, 1190], 'SBC022.trn': [5, 23, 316, 336, 366, 367, 404, 405, 418, 453], 'SBC023.trn': [193, 438, 911, 920, 991, 1177, 1353, 1391, 1394], 'SBC024.trn': [80, 742, 869, 871], 'SBC029.trn': [58, 67, 256, 258, 348, 416, 427, 534, 732, 798, 799, 981, 982, 1011, 1082, 1097], 'SBC031.trn': [45, 47, 162, 191, 291, 346, 360, 390, 563, 598, 600, 1370, 1488, 1489, 1510, 1511], 'SBC032.trn': [84, 345, 346, 582, 583, 849, 1306, 1368, 1487, 1793, 1834], 'SBC033.trn': [33, 34, 338, 393, 508, 522], 'SBC034.trn': [26, 360, 504, 553], 'SBC035.trn': [157, 178, 228, 291, 292, 302, 469, 584, 619, 814, 1054, 1118, 1143, 1201, 1226, 1293], 'SBC036.trn': [10, 53, 108, 378, 395, 468, 1154, 1294, 1794, 1796, 1797], 'SBC037.trn': [86, 428, 528, 579, 629, 644, 663], 'SBC042.trn': [457, 679], 'SBC043.trn': [19, 80, 95, 114, 247, 310, 311, 413, 442, 444, 488, 550, 847, 855, 1001, 1012, 1015, 1016, 1038, 1090, 1445, 1455, 1457, 1460, 1461, 1485], 'SBC044.trn': [113, 128, 129, 194, 266, 440, 448, 1348, 1366, 1394], 'SBC045.trn': [123, 852], 'SBC047.trn': [156, 157, 328, 347, 896, 919, 922, 1010, 1058, 1071, 1100, 1103, 1109, 1157], 'SBC048.trn': [151, 152, 166, 286, 296, 414, 415, 417, 838, 842, 908, 926, 1000, 1002, 1011, 1025], 'SBC049.trn': [24, 126, 159, 449, 991, 1035, 1041, 1182], 'SBC050.trn': [19, 29, 90, 117, 175, 186, 273, 483, 486, 722, 798, 799, 807, 810, 931], 'SBC051.trn': [845, 1229, 1509, 1669], 'SBC056.trn': [89, 273, 282, 344, 345, 346, 411, 522, 533, 656, 765, 792, 793, 794, 802, 1026, 1229, 1238, 1470], 'SBC057.trn': [117, 193, 300, 330, 526, 716, 967, 974, 990], 'SBC058.trn': [12, 122, 311, 344, 429, 564, 751, 863], 'SBC059.trn': [567, 569, 625, 628, 637, 696, 700, 713, 715, 983, 1048, 1049, 1160, 1286, 1336, 1384, 1607, 1637], 'SBC060.trn': [652, 654, 672, 800, 808, 995, 996]}\n"
     ]
    }
   ],
   "source": [
    "indices = {key: [tpl[0] for tpl in value] for key, value in goods.items()}\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e2e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('goods_output.txt', 'w') as file:\n",
    "    import sys\n",
    "    sys.stdout = file\n",
    "    \n",
    "    for index in indices:\n",
    "        df = dfs[index]\n",
    "        print(index)\n",
    "        key = index\n",
    "        values = indices[key]\n",
    "        for v in values:\n",
    "            first = v - 10\n",
    "            last = v + 10\n",
    "            print(df.iloc[first:last])\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450de22",
   "metadata": {},
   "source": [
    "## Pipeline for outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aa31233",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [likes, loves, wells, fines, goods, greats, rights, imeans]\n",
    "targets_str = ['likes', 'loves', 'wells', 'fines', 'goods', 'greats', 'rights', 'imeans']\n",
    "count = 0\n",
    "\n",
    "for target in targets:\n",
    "    # establish indices\n",
    "    indices = {key: [tpl[0] for tpl in value] for key, value in target.items()}\n",
    "    \n",
    "    # write out file\n",
    "    with open(targets_str[count]+\"_output.txt\", 'w') as file:\n",
    "    \n",
    "        import sys\n",
    "        sys.stdout = file\n",
    "        \n",
    "        for index in indices:\n",
    "            df = dfs[index]\n",
    "            print(index)\n",
    "            key = index\n",
    "            values = indices[key]\n",
    "            # give 20 lines of context\n",
    "            for v in values:\n",
    "                first = v - 10\n",
    "                last = v + 10\n",
    "                print(df.iloc[first:last])\n",
    "    count+=1\n",
    "            \n",
    "    sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
